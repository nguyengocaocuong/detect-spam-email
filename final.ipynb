{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from statistics import mean\n",
    "from shutil import move\n",
    "import json\n",
    "import os\n",
    "import joblib\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id label                                               text  label_num\n",
      "0   605   ham  Subject: enron methanol ; meter # : 988291\\r\\n...          0\n",
      "1  2349   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...          0\n",
      "2  3624   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...          0\n",
      "3  4685  spam  Subject: photoshop , windows , office . cheap ...          1\n",
      "4  2030   ham  Subject: re : indian springs\\r\\nthis deal is t...          0\n"
     ]
    }
   ],
   "source": [
    "input_emails = pd.read_csv(\"./data/spam_ham_dataset.csv\")\n",
    "print(input_emails.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Feature:  17393\n"
     ]
    }
   ],
   "source": [
    "def extract_feature(input_emails):\n",
    "    stopwords_ = stopwords.words(\"english\")\n",
    "    porterStemmer = PorterStemmer()\n",
    "    count_words = {}\n",
    "    for i in range(len(input_emails)):\n",
    "        email = input_emails[i]\n",
    "        words = [w for w in word_tokenize(email[2][9:]) if not w in stopwords_]\n",
    "        words = [porterStemmer.stem(w) for w in words]\n",
    "\n",
    "        for word in words:\n",
    "            if word.isalpha() and len(word) > 1:\n",
    "                if count_words.get(word):\n",
    "                    count_words[word] += 1\n",
    "                else:\n",
    "                    count_words[word] = 1\n",
    "   \n",
    "    set_words =  [key for key in count_words.keys() if count_words[key] > 1]\n",
    "    with open(\"./data/set_words.txt\", \"w\") as file:\n",
    "        json.dump(set_words,file)\n",
    "    print(\"Number of Feature: \",len(set_words))\n",
    "extract_feature(input_emails.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matrixs(input_emails):\n",
    "    matrixs = []\n",
    "    labels = []\n",
    "    set_words = []\n",
    "    stopwords_ = stopwords.words(\"english\")\n",
    "    porterStemmer = PorterStemmer()\n",
    "    with open(\"./data/set_words.txt\") as file:\n",
    "        set_words = json.load(file)\n",
    "    for i in range(len(input_emails)):\n",
    "        email = input_emails[i]\n",
    "        words = [w for w in word_tokenize(email[2][9:]) if not w in stopwords_]\n",
    "        vector = [0 for i in range(len(set_words))]\n",
    "\n",
    "        for w in words:\n",
    "            w = porterStemmer.stem(w)\n",
    "            if w in set_words:\n",
    "                vector[set_words.index(w)] += 1\n",
    "        matrixs.append(vector)\n",
    "        labels.append(email[-1])\n",
    "    return matrixs, labels\n",
    "\n",
    "matrixs, labels = create_matrixs(input_emails.to_numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_email(email):\n",
    "    matrixs = []\n",
    "    set_words = []\n",
    "    stopwords_ = stopwords.words(\"english\")\n",
    "    porterStemmer = PorterStemmer()\n",
    "    with open(\"./data/set_words.txt\") as file:\n",
    "        set_words = json.load(file) \n",
    "    words = [w for w in word_tokenize(email[9:]) if not w in stopwords_]\n",
    "    vector = [0 for i in range(len(set_words))]\n",
    "    for w in words:\n",
    "        w = porterStemmer.stem(w)\n",
    "        if w in set_words:\n",
    "            vector[set_words.index(w)] += 1\n",
    "    matrixs.append(vector)\n",
    "    return matrixs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9671814671814671, 0.9748549323017408, 0.9690522243713733, 0.97678916827853, 0.9671179883945842, 0.9729206963249516, 0.9613152804642167, 0.9787234042553191, 0.9806576402321083, 0.9729206963249516]\n",
      "Max score:  0.9721533498129242\n",
      "Min score:  0.9721533498129242\n",
      "Mean score:  0.9721533498129242\n"
     ]
    }
   ],
   "source": [
    "def train_model_and_save():\n",
    "    matrixs = []\n",
    "    labels = []\n",
    "    if not os.path.exists(\"./data/matrixs.npy\") or not os.path.exists(\"./data/labels.npy\"):\n",
    "        input_emails = pd.read_csv(\"./data/spam_ham_dataset.csv\").to_numpy()\n",
    "        matrixs, labels = create_matrixs(input_emails)\n",
    "\n",
    "        np.save('./data/matrixs.npy', matrixs)\n",
    "        np.save('./data/labels.npy', labels)\n",
    "    else:\n",
    "        matrixs = np.load(\"./data/matrixs.npy\")\n",
    "        labels = np.load(\"./data/labels.npy\")\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "    lst_accu_stratified = []\n",
    "    multinomialNB = MultinomialNB()\n",
    "    max = []\n",
    "    x = 0\n",
    "    for train_index, test_index in skf.split(matrixs, labels):\n",
    "        x_train, x_test = matrixs[train_index], matrixs[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        multinomialNB.fit(x_train, y_train)\n",
    "        sccore = multinomialNB.score(x_test, y_test)\n",
    "        if x == 0 or x < sccore:\n",
    "            max = []\n",
    "            x = sccore\n",
    "            max.append(x_train)\n",
    "            max.append(y_train)\n",
    "            max.append(x_test)\n",
    "            max.append(y_test)\n",
    "        lst_accu_stratified.append(sccore)\n",
    "    print(lst_accu_stratified)\n",
    "    print(\"Max score: \",mean(lst_accu_stratified))\n",
    "    print(\"Min score: \",mean(lst_accu_stratified))\n",
    "    print(\"Mean score: \",mean(lst_accu_stratified))\n",
    "    multinomialNB = multinomialNB.fit(max[0], max[1])\n",
    "    joblib.dump(multinomialNB, f\"./data/model_detect_spam_email_NB.joblib\")\n",
    "\n",
    "train_model_and_save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. email_1.txt\n",
      "2. email_2.txt\n",
      "3. email_3.txt\n",
      "4. email_4.txt\n",
      "5. email_5.txt\n",
      "6. email_6.txt\n",
      "0. Exist\n",
      "Enter you email number: \n",
      "===================\n",
      "Email : Subject: re : indian springs\n",
      "this deal is to book the teco pvr revenue . it is my understanding that teco\n",
      "just sends us a check , i haven ' t received an answer as to whether there is a\n",
      "predermined price associated with this deal or if teco just lets us know what\n",
      "we are giving . i can continue to chase this deal down if you need .\n",
      "-------------------\n",
      "\tHam email\n",
      "===================\n",
      "1. email_2.txt\n",
      "2. email_3.txt\n",
      "3. email_4.txt\n",
      "4. email_5.txt\n",
      "5. email_6.txt\n",
      "0. Exist\n",
      "Enter you email number: \n",
      "===================\n",
      "Email : Subject: spring savings certificate - take 30 % off\n",
      "save 30 % when you use our customer appreciation spring savings\n",
      "certificate at foot locker , lady foot locker , kids foot locker and at\n",
      "our online stores !\n",
      "welcome to our customer appreciation spring savings certificate !\n",
      "use the special certificate below and receive 30 % off your purchases either in our stores or online . hurry ! this 4 - day sale begins thursday , march 22 and ends sunday , march 25 .\n",
      "share the savings today and e - mail this offer to your friends . many items already are reduced and the 30 % discount is taken off the lowest sale price .\n",
      "click below to print your customer appreciation spring savings certificate . you must present this coupon at any foot locker , lady foot locker or kids foot locker store in the u . s . foot locker canada is not participating in this program .\n",
      "ready , set , save !\n",
      "our spring savings discount will automatically appear when you use the links below or type camlem 21 into the promotion code box during checkout .\n",
      "footlocker . com certificate code : camlem 21\n",
      "ladyfootlocker . com certificate code : camlem 21\n",
      "kidsfootlocker . com certificate code : camlem 21\n",
      "remember , returns are hassle - free . simply bring your items to any of our stores nationwide or through the mail .\n",
      "don ' t be left out - register today to learn about our new products , promotions , events and other specials . simply click below .\n",
      "terms and conditions . some exclusions apply , please see manager for complete details . certificate must be presented at the time of purchase and cannot be used in conjunction with any other discount offer or associate benefit . not redeemable for cash . applicable taxes must be paid by bearer . cannot be applied to prior purchases or to gift card purchases . void where prohibited , licensed or regulated . catalog exclusions apply . valid thursday , 3 / 22 / 01 through sunday , 3 / 25 / 01 . foot locker canada will not participate in this program .\n",
      "if you do not wish to receive future emails please click below to\n",
      "unsubscribe :\n",
      "-------------------\n",
      "\tHam email\n",
      "===================\n",
      "1. email_3.txt\n",
      "2. email_4.txt\n",
      "3. email_5.txt\n",
      "4. email_6.txt\n",
      "0. Exist\n",
      "Enter you email number: \n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    email_number = -1\n",
    "    model = joblib.load(\"./data/model_detect_spam_email_NB.joblib\")\n",
    "    while True:\n",
    "        list_files = os.listdir(\"./data/test_email/\")\n",
    "        for i in range(len(list_files)):\n",
    "            print(f\"{i+1}. {list_files[i]}\")\n",
    "        print(\"0. Exist\")\n",
    "        print(\"Enter you email number: \")\n",
    "        email_number = int(input())\n",
    "        if email_number == 0:\n",
    "            break\n",
    "        email = \"\"\n",
    "        with  open(f\"./data/test_email/{list_files[email_number-1]}\") as file:\n",
    "            email = file.read()\n",
    "        matrixs = prepare_email(email)\n",
    "        y_pred = model.predict(matrixs)\n",
    "        print(\"===================\")\n",
    "        print(f\"Email : {email}\")\n",
    "        print(\"-------------------\")\n",
    "        if y_pred[0] == 0:\n",
    "            print(\"\\tHam email\")\n",
    "        else:\n",
    "            print(\"\\tSpam email\")\n",
    "        print(\"===================\")\n",
    "\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9121c89f9934acd00561cd54525e16717599c67e6e0655945e2fcf5b4dea365d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

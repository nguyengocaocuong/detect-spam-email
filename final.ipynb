{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from statistics import mean\n",
    "from shutil import move\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import joblib\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_emails = pd.read_csv(\"./data/spam_ham_dataset.csv\")\n",
    "print(input_emails.head())\n",
    "print(input_emails.describe())\n",
    "print(input_emails.groupby(\"label\").describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(input_emails):\n",
    "    stopwords_ = stopwords.words(\"english\")\n",
    "    porterStemmer = PorterStemmer()\n",
    "    count_words = {}\n",
    "    for i in range(len(input_emails)):\n",
    "        email = input_emails[i]\n",
    "        words = [w for w in word_tokenize(email[2][9:]) if not w in stopwords_]\n",
    "        words = [porterStemmer.stem(w) for w in words]\n",
    "\n",
    "        for word in words:\n",
    "            if word.isalpha() and len(word) > 1:\n",
    "                if count_words.get(word):\n",
    "                    count_words[word] += 1\n",
    "                else:\n",
    "                    count_words[word] = 1\n",
    "   \n",
    "    set_words =  [key for key in count_words.keys() if count_words[key] > 1]\n",
    "    with open(\"./data/set_words.txt\", \"w\") as file:\n",
    "        json.dump(set_words,file)\n",
    "    print(\"Number of Feature: \",len(set_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matrixs(input_emails):\n",
    "    matrixs = []\n",
    "    labels = []\n",
    "    set_words = []\n",
    "    stopwords_ = stopwords.words(\"english\")\n",
    "    porterStemmer = PorterStemmer()\n",
    "    with open(\"./data/set_words.txt\") as file:\n",
    "        set_words = json.load(file)\n",
    "    for i in range(len(input_emails)):\n",
    "        email = input_emails[i]\n",
    "        words = [w for w in word_tokenize(email[2][9:]) if not w in stopwords_]\n",
    "        vector = [0 for i in range(len(set_words))]\n",
    "\n",
    "        for w in words:\n",
    "            w = porterStemmer.stem(w)\n",
    "            if w in set_words:\n",
    "                vector[set_words.index(w)] += 1\n",
    "        matrixs.append(vector)\n",
    "        labels.append(email[-1])\n",
    "    return matrixs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_email(email):\n",
    "    matrixs = []\n",
    "    set_words = []\n",
    "    stopwords_ = stopwords.words(\"english\")\n",
    "    porterStemmer = PorterStemmer()\n",
    "    with open(\"./data/set_words.txt\") as file:\n",
    "        set_words = json.load(file) \n",
    "    words = [w for w in word_tokenize(email[9:]) if not w in stopwords_]\n",
    "    vector = [0 for i in range(len(set_words))]\n",
    "    for w in words:\n",
    "        w = porterStemmer.stem(w)\n",
    "        if w in set_words:\n",
    "            vector[set_words.index(w)] += 1\n",
    "    matrixs.append(vector)\n",
    "    return matrixs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_and_save(input_emails):\n",
    "    matrixs = []\n",
    "    labels = []\n",
    "    if not os.path.exists(\"./data/matrixs.npy\") or not os.path.exists(\"./data/labels.npy\"):\n",
    "        input_emails = pd.read_csv(\"./data/spam_ham_dataset.csv\").to_numpy()\n",
    "        matrixs, labels = create_matrixs(input_emails)\n",
    "\n",
    "        np.save('./data/matrixs.npy', matrixs)\n",
    "        np.save('./data/labels.npy', labels)\n",
    "    else:\n",
    "        matrixs = np.load(\"./data/matrixs.npy\")\n",
    "        labels = np.load(\"./data/labels.npy\")\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    lst_accu_stratified = []\n",
    "    multinomialNB = MultinomialNB()\n",
    "    max = []\n",
    "    x = 0\n",
    "    for train_index, test_index in skf.split(matrixs, labels):\n",
    "        x_train, x_test = matrixs[train_index], matrixs[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        multinomialNB.fit(x_train, y_train)\n",
    "        sccore = multinomialNB.score(x_test, y_test)\n",
    "        if x == 0 or x < sccore:\n",
    "            max = []\n",
    "            x = sccore\n",
    "            max.append(x_train)\n",
    "            max.append(y_train)\n",
    "            max.append(x_test)\n",
    "            max.append(y_test)\n",
    "        lst_accu_stratified.append(sccore)\n",
    "    print(lst_accu_stratified)\n",
    "    # print(\"Max score: \",max(lst_accu_stratified))\n",
    "    # print(\"Min score: \",min(lst_accu_stratified))\n",
    "    print(\"Mean score: \",mean(lst_accu_stratified))\n",
    "    multinomialNB = multinomialNB.fit(max[0], max[1])\n",
    "    joblib.dump(multinomialNB, f\"./data/model_detect_spam_email_NB.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    if not os.path.exists(\"./data/model_detect_spam_email_NB.joblib\"):\n",
    "        input_emails = pd.read_csv(\"./data/spam_ham_dataset.csv\")\n",
    "        print(\"Start training model detect email....\")\n",
    "        train_model_and_save(input_emails.to_numpy())\n",
    "        print(\"Done....\")\n",
    "\n",
    "    email_number = -1\n",
    "    model = joblib.load(\"./data/model_detect_spam_email_NB.joblib\")\n",
    "    while True:\n",
    "        list_files = os.listdir(\"./data/test_email/\")\n",
    "        for i in range(len(list_files)):\n",
    "            print(f\"{i+1}. {list_files[i]}\")\n",
    "        print(\"0. Exist\")\n",
    "        print(\"Enter you email number: \")\n",
    "        email_number = int(input())\n",
    "        print(email_number)\n",
    "        if email_number == 0:\n",
    "            break\n",
    "        email = \"\"\n",
    "        with  open(f\"./data/test_email/{list_files[email_number-1]}\") as file:\n",
    "            email = file.read()\n",
    "        matrixs = prepare_email(email)\n",
    "        y_pred = model.predict(matrixs)\n",
    "        print(\"===================\")\n",
    "        print(f\"Input : {list_files[email_number-1]}\")\n",
    "        if y_pred[0] == 0:\n",
    "            print(\"\\tResult: Ham email\")\n",
    "        else:\n",
    "            print(\"\\tResult: Spam email\")\n",
    "        print(\"===================\")\n",
    "\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9121c89f9934acd00561cd54525e16717599c67e6e0655945e2fcf5b4dea365d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
